\ch{Intuitionistic logic}
\label{ch:booleans}
\label{booleans}
\label{ch:bools}
\label{bools}
\label{ch:props}
\label{props}

For a long time, mathematicians would deal with statements that were either
true or false. This was called \term{classical logic}. 

In the 1930s, a man named Kurt \godel\ proved a rather shocking fact: in any
non-trivial formal arithmetic system, there will always be statements that are
true, but cannot be proven. So, if we can't \xtb{prove} something, how do we
know whether or not it's true?

\begin{asidebox}
    \godel\ was somewhat of a character. He was extremely paranoid about being
    poisoned, so he refused to eat anything unless his wife prepared it for him.
    Towards the end of his life, his wife was hospitalized for an extensive
    period of time, during which \godel\ refused to eat, and therefore starved
    to death. \cite{w-godel}
\end{asidebox}

Well, the answer is to not think of things in terms of \term{true} and
\term{false}, but rather in the terms of \term{provable} and
\term{unprovable}. Anything that's provable is true. Anything that isn't
provable, we don't care whether or not it's true, because we can't prove it.
\nocite{w-godel-incompleteness}

Further supporting this line of thinking is the liar's paradox:

\begin{quote}
    This statement is false.
\end{quote}

If we assume that the statement is true, then the statement makes itself
false. If you assume the statement is false, it makes itself true. This is an
example of a statement that cannot be said to be true or false. There are
similar statements in math, were we can't even say it's true or false.

In the case of the liar's paradox, we have a pretty quick cop-out, by just
saying that it's not provable. We don't care whether or not it's true.

For this, we have two values in math, which we throw around a lot: $\top$, and
$\bot$. The symbols are called \term{top} and \term{bottom}, respectively. They
refer, respectively to `provable' and `unprovable'.

\xtb{Why don't you just call the symbols `provable' and `unprovable'?}

It's sort of like how $+$ and $-$ refer to the concepts addition and
subtraction, but are pronounced `plus' and `minus'.

You're probably still used to calling propositions `true' and `false'. That's
okay. Over time, you'll get used to calling them `provable' and
`unprovable'. Even mathematicians will accidentally call them `true' and
`false'.

\ss{If A then B; A, therefore B.}

This is pretty simple notation, actually.

\begin{equation}
    \label{eq:aimpliesb}
    A \implies B
\end{equation}

The above is pretty intuitive: if $A$ is true, then $B$ is true.

Now, actually, you shouldn't say true or false. Let's try that again

\begin{equation}
    \label{eq:aimpliesb}
    A \implies B
\end{equation}

The $\implies$ symbol is usually pronounced ``implies''. So, $A$ implies $B$.
Note that this \xtb{does not} mean that $B$ implies $A$.

A common mistake is to say ``Well, if $A$ happens, then $B$ will happen. If I
know that $B$ happened, then I can reasonably conclude that $A$ happened at some
point in the past.''

Let's go through an example to show why this doesn't quite work.

If someone is decapitated, then they are dead, at least within a few seconds.

\begin{equation}
    \label{eq:decapdead}
    \text{Decapitated} \implies \text{Dead}
\end{equation}

\answergraph{alas-poor-yorick-5.png}

However, if someone is dead, it doesn't necessarily mean they were
decapitated. They could have been shot, stabbed, had a heart attack, been hit by
a bus; there are endless possibilities. Thus,

\begin{equation}
    \label{eq:notdeaddecap}
    \text{Decapitated} \notimpliedby \text{Dead}
\end{equation}

However, if someone is \xtb{not} dead, then they obviously weren't
decapitated. Therefore,

\begin{equation}
    \label{eq:notdeaddecap}
    \lnot\text{Decapitated}\impliedby\lnot\text{Dead}
\end{equation}

This is a fundamental rule of logic, called the \term{contraposition} (or,
marginally more pretentiously, \term{modus tollens}):

\begin{equation}
    \label{eq:contraposition}
    \parens{A \implies B} \implies \parens{\lnot B \implies \lnot A}
\end{equation}

In some cases, such as the decapitation + death example, it's pretty obvious
that $A$ implies $B$ However, in most cases, it's not obvious. In which case,
you need to provide a \term{proof}. Now, how do you prove something in math?

It's not all that hard usually. You state what you know, and then you combine
those facts together.

Let's look through a reasonably simple proof.

\begin{textmath}
    For all $A$ and $B$

    \begin{equation}
        A \implies \parens{\parens{A \implies B} \implies B}
    \end{equation}

    Instead of writing ``for all'', most mathematicians will use the symbol
    $\forall$. It sort of looks like an $A$, and it's much more convenient to
    write than typing out ``for all'' every time. The above proposition should
    now be written 

    In slightly less abstract notation: if we have a proof of $A$, then a proof
    that $A \implies B$ means that $B$ is provable.

    \begin{equation}
        A \implies \parens{\parens{A \implies B} \implies B}
    \end{equation}

    If you reverse the order of the first two conditions, then you get

    \begin{equation}
        \label{eq:abimplies}
        \parens{A \implies B} \implies \parens{A \implies B}
    \end{equation}

    But that's too easy and therefore no fun.

    Throughout the book, you will see a block of text begin with \xti{Proof} and
    end with a white box: \qed

    This is standard mathematical notation. The white box means ``proof
    completed''. You'll often see the term QED floated around a lot. It's an
    acronym for quod erat demonstrandum, which means ``end of demonstration'' in
    Latin. Again, mathematicians love to use fancy Latin phrases to make
    themselves look smart.
\end{textmath}

\begin{proof}
    \begin{equation}
        A \implies \parens{\parens{A \implies B} \implies B} \sfall A, B
    \end{equation}

    For giggles, let's give the proof a name: \nmtext{foo}. We don't know what
    \nmtext{foo} is, but we know that it's a proof of
    $A \implies \parens{\parens{A \implies B} \implies B}$.

    To express this, you have the colon ($:$) at your disposal

    \begin{equation}
        \text{foo} : \forall A,B ;\; A \implies \parens{\parens{A \implies B} \implies B}
    \end{equation}

    Think about this: $A \implies \dots$. This is equivalent to saying ``if I
    have a proof of $A$, then \dots''. So, we can therefore give the proof of
    $A$ an arbitrary name. I'm going to call it $f$.

    \begin{alignedmath}
        f : A \\
        \hrulefill \\
        \parens{A \implies B} \implies B \\
    \end{alignedmath}

    Above the line is what we know, and below the line is what we are trying to
    prove.

    Again, on the portion below the line, we are trying to prove the stuff after
    the arrow, assuming the stuff before the arrow is true. Thus, in the
    expression below the line, we can move the thing before the first arrow to
    be above the line.
    
    \begin{alignedmath}
        f : A \\
        g : A \implies B \\
        \hrulefill \\
        B \\
    \end{alignedmath}

    So, $g$ is a proof that $A \implies B$. Again, we don't care what the proof
    is. The best part about proofs is that you get to assume that the stuff
    before the arrow is already proven.

    $B$ doesn't have any arrows, so it looks like we have to prove $B$. Well,
    $g$ is sitting there hoping that there's a proof of $A$ laying around so
    that it can prove $B$.

    Oh wait, there is!

    So, we can feed $g$ (a proof that $A \implies B$) our proof of $A$ (which is
    $f$). How do we express this notion of ``feeding''?

    \begin{alignedmath}
        f : A \\
        g : A \implies B \\
        \eva{g}{f} : B \\
        \hrulefill \\
    \end{alignedmath}

    Now, there's nothing below the line, so we're done!
\end{proof}

Alright, that was pretty hard! I can almost guarantee you didn't understand that
the first time. It's an entirely new concept! Go take a coffee break, take a
walk, or something of the like, come back in an hour, and read over the
explanation again. I bet it'll be a lot easier to understand the second time
around.

I'm even going to write the following stuff on a new page so you aren't as
tempted to keep going.

\newpage

Well, I lied, w


% \begin{textmath}
%     For all $A$, $B$, and $C$,

%     \begin{equation}
%         A \implies \parens{\parens{A \implies \parens{B \implies C}} \implies \parens{B \implies C}}
%     \end{equation}

% \end{textmath}

% \begin{proof}
%     That looks scary, but it's really not.

%     When your proof starts with ``for all'', you should start by assigning
%     everything a name. Instead of proving that the property holds for \xtb{all}
%     $A$, $B$, and $C$, we'll pick \xtb{any} arbitrary $A$, and call it $f$, and
%     show that the rest of the property holds.

%     That might not make sense. Let me show you.

%     Let's start by assigning all of the values names:

%     \begin{alignedmath}
%         f : A \\
%         \hrulefill \\
%         g : \parens{A \implies \parens{B \implies C}} \implies \parens{B \implies C} \\
%     \end{alignedmath}

%     In this proof, given that we know the stuff above the line is true, we have
%     to prove what's below the line.

%     In this case, $f$ is any proof of $A$. It doesn't actually matter what $f$
%     is, just that it is a proof of $A$. 

%     So, now, what we're trying to prove is that, for any pair $f$ and $g$ that
%     we choose:

%     \begin{equation}
%         f \implies g
%     \end{equation}

%     Which definitely looks easier.

%     Let's split $g$ up some more:

%     \begin{alignedmath}
%         f : A \\
%         \hrulefill \\
%         \hspace{1cm} h : A \implies \parens{B \implies C} \\
%         \hspace{1cm} \hrulefill \\
%         \hspace{1cm} j : B \implies C \\
%     \end{alignedmath}

%     Well, we don't really need the line there, because in the case of trying to
%     prove that $h \implies j$, we only are trying to prove this in the context
%     of having a proof of $f$. So, in the limited context of $h \implies j$, we
%     can assume $f$:

%     \begin{alignedmath}
%         f : A \\
%         h : A \implies \parens{B \implies C} \\
%         \hrulefill \\
%         j : B \implies C \\
%     \end{alignedmath}

%     I'm skipping over $i$ here because it's often hard to quickly spot the
%     difference between $ilI1|$ with the normal font. In monospace:
%     \terminal{ilI1|}.

%     Now, we have to split this up some more!

%     \begin{alignedmath}
%         f : A \\
%         h : A \implies \parens{B \implies C} \\
%         k : B \\
%         \hrulefill \\
%         m : C \\
%     \end{alignedmath}

%     Let's take a look at this point.

%     \begin{itemize}
%       \item $f$ is a proof of $A$
%       \item $k$ is a proof of $B$
%       \item $h$ is a proof of $A \to \parens{B \to C}$. Or rather, given a proof
%         of $A$, $h$ will give you a proof of $B \implies C$.
%     \end{itemize}

%     You're probably asking: why don't I split up 

%     Remember, $h$ takes a proof of $A$. It does not take $A$ itself, but rather
%     a proof of it.

%     So, let's ``apply'' the proof of $f$ to the proof $h$. That is, see what
%     happens to $h$ if we assume $f$:

%     \begin{equation}
%         \eva{h}{f} : B \implies C
%     \end{equation}


%     Let's add it to the list:

%     \begin{alignedmath}
%         f : A \\
%         h : A \implies \parens{B \implies C} \\
%         k : B \\
%         \eva{h}{f} : B \implies C \\
%         \hrulefill \\
%         m : C \\
%     \end{alignedmath}

%     (Again, skipping over $l$ for the same reason I skipped over $i$).

%     Well, now we can just do $\eva{\eva{h}{f}}{k}$, to get a proof of
%     $C$. $\eva{\eva{h}{f}}{k}$ is a bit cumbersome, so I'll just write
%     $\eva{h}{f,k}$.

%     \begin{alignedmath}
%         f : A \\
%         h : A \implies \parens{B \implies C} \\
%         k : B \\
%         \eva{h}{f} : B \implies C \\
%         \eva{h}{f,k} : C \\
%         \hrulefill \\
%         m : C \\
%     \end{alignedmath}

%     Our proof is quite simple: 

%     \begin{equation}
%         A \implies \parens{\parens{A \implies \parens{B \implies C}} \implies \parens{B \implies C}}
%     \end{equation}

%     Split into sub-goals:

%     \begin{alignedmath}
%         f : A \\
%         h : A \implies \parens{B \implies C} \\
%         k : B \\
%         \hrulefill \\
%         m : C \\
%     \end{alignedmath}

%     Then, apply the proofs to other proofs:

%     \begin{alignedmath}
%         \eva{h}{f,k} : C
%     \end{alignedmath}

%     Done. As mathematicians like to say: QED. QED stands for \term{quod erat
%       demonstrandum}, which means ``end of demonstration'' in Latin. Again,
%     mathematicians love to be pretentious by using Latin phrases when English
%     would do just as well.
% \end{proof}

% Phew! That was hard, even for me, and I'm writing it! Go take a walk, have a
% coffee, come back in an hour, and read it again. It will make a lot more sense
% next time.

\newpage
\s{Alright, I'm done with my walk.}

Let's go back:

% \input{2/1-props.ltx}
% \input{2/2-bools-monoids.ltx}